revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+06:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+06:00"] + 6*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+07:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+07:00"] + 7*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+08:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+08:00"] + 8*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:00"] + 9*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:30"] + 9*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:00"] + 10*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:30"] + 10*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+11:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+11:00"] + 11*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+12:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+12:00"] + 12*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-01:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-01:00"] - 3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-02:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-02:00"] - 2*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:00"] - 3*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:30"] - 3*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-04:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-04:00"] - 4*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-05:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-05:00"] - 5*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-06:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-06:00"] - 6*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-07:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-07:00"] - 7*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-08:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-08:00"] - 8*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-09:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-09:00"] - 9*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-10:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-10:00"] - 10*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-11:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-11:00"] - 11*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-12:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-12:00"] - 12*3600
# Add the weekday and hour based on Madrid time to be consistent with NGU analysis
revenues_benchmark2$wday <- as.POSIXlt(revenues_benchmark2$datetime)$wday
revenues_benchmark2$hour <- unlist(strsplit(as.character(revenues_benchmark2$datetime), " "))[seq(2,length(revenues_benchmark2$datetime)*2,by = 2)]
revenues_benchmark2$hour <- as.character(revenues_benchmark2$hour) # Convert factors to characters
### Add revenues per hour to bm2 data
# Adding the average revenues for each hour period
bm2_unique_hours_periods$Total_revenues <- rep(0, nrow(bm2_unique_hours_periods))
for(r in 1:nrow(bm2_unique_hours_periods)) {
bm2_unique_hours_periods$Total_revenues[r] <- sum(revenues_benchmark2$net_value[as.POSIXlt(revenues_benchmark2$datetime)$hour==bm2_unique_hours_periods$hour[r] &
as.POSIXlt(revenues_benchmark2$datetime)$wday==bm2_unique_hours_periods$day[r]])
}
# Calculating average revenues per hour and per minute for each hour period
bm2_unique_hours_periods$Avg_revenues_per_HOUR <- bm2_unique_hours_periods$Total_revenues/bm2_unique_hours_periods$occurences
bm2_unique_hours_periods$Avg_revenues_per_MINUTE <- bm2_unique_hours_periods$Avg_revenues_per_HOUR/60
# DOWNLOAD CAMPAIGN MARKETING TRACKED DATA ----------------------------------------------------------------------------------------
cat("DOWNLOAD MARKETING TRACKED USER REVENUES DATA FROM REDSHIFT")
cat("\n")
campaign_query_marketing_tracked_user_revenues <- paste( "SELECT convert_timezone('UTC','Europe/Madrid', t_transaction.datetime) as datetime, t_transaction.ip_timezone, COALESCE(t_transaction.amount_gross*0.7, 0) AS net_value
FROM ",schema,".t_transaction
LEFT JOIN ",schema,".log_session_start
ON t_transaction.session_id = log_session_start.session_id
AND t_transaction.user_id = log_session_start.user_id
LEFT JOIN ",schema,".t_user
ON t_transaction.user_id = t_user.user_id
WHERE t_transaction.datetime >= '", query_start_date, "'
AND t_transaction.datetime <= '", query_end_date, "'
AND lower(t_user.register_source) in ", marketing_tracker_source, "
AND (t_transaction.offer != 'earncash' OR t_transaction.offer IS NULL)
AND t_transaction.platform = '", platform, "'
AND t_transaction.ip_country = '", country,"'
AND date_add('d', -1, '", query_start_date, "') <= log_session_start.datetime
AND log_session_start.datetime <= '", query_end_date, "'", sep = "")
revenues_campaign_marketing_tracked_installs <- dbGetQuery(spdb, campaign_query_marketing_tracked_user_revenues)
# Add a column with the real date of the country of install and the weekday
revenues_campaign_marketing_tracked_installs$real_date <- revenues_campaign_marketing_tracked_installs$datetime
# ATTRIBUTION ANALYSIS --------------------------------------------------------------------------------------------------
cat("ATTRIBUTION ANALYSIS")
cat("\n")
## PER HOUR ANALYSIS
# Separate analysis period into hours
revenues_per_hour <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-60*60), by = "hour"))
colnames(revenues_per_hour) <- "hour_start"
revenues_per_hour$hour_end <- revenues_per_hour$hour_start+60*60
# Add benchmark revenues per hour
revenues_per_hour$revenues_benchmark <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
revenues_per_hour$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_hour$hour_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_hour$hour_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_hour$revenues_benchmark[revenues_per_hour$revenues_benchmark==0] <- 0.1
# Add actual revenues per hour
revenues_per_hour$revenues_actual <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
revenues_per_hour$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_hour$hour_start[r] & revenues_campaign$datetime <= revenues_per_hour$hour_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_hour$revenues_if_no_campaign <- rep(revenues_per_hour$revenues_actual[1], nrow(revenues_per_hour))
for(r in 2:nrow(revenues_per_hour)) {
if(revenues_per_hour$hour_end[min(r+1,nrow(revenues_per_hour))] <= campaign_start) {
revenues_per_hour$revenues_if_no_campaign[r] <- revenues_per_hour$revenues_actual[r]
} else {
revenues_per_hour$revenues_if_no_campaign[r] <- min(revenues_per_hour$revenues_actual[r],
revenues_per_hour$revenues_if_no_campaign[r-1]*revenues_per_hour$revenues_benchmark[r]/revenues_per_hour$revenues_benchmark[r-1])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_hour$revenues_benchmark2 <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
if(revenues_per_hour$hour_end[min(r+1,nrow(revenues_per_hour))] <= campaign_start) {
revenues_per_hour$revenues_benchmark2[r] <- revenues_per_hour$revenues_actual[r]
} else {
revenues_per_hour$revenues_benchmark2[r] <- bm2_unique_hours_periods$Avg_revenues_per_HOUR[bm2_unique_hours_periods$hour==as.POSIXlt(revenues_per_hour$hour_start[r])$hour & bm2_unique_hours_periods$day==as.POSIXlt(revenues_per_hour$hour_start[r])$wday]
}
}
# Add time since campaign column
revenues_per_hour$time_since_campaign <- time_length((revenues_per_hour$hour_start - as.POSIXct(campaign_start)), "hours")
## PER DAY ANALYSIS
# Separate analysis period into days
revenues_per_day <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-24*60*60), by = "day"))
colnames(revenues_per_day) <- "day_start"
revenues_per_day$day_end <- revenues_per_day$day_start+24*60*60
# Add benchmark revenues per day
revenues_per_day$revenues_benchmark <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_day$day_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_day$day_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_day$revenues_benchmark[revenues_per_day$revenues_benchmark==0] <- 0.1
# Add actual revenues per day
revenues_per_day$revenues_actual <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_day$day_start[r] & revenues_campaign$datetime <= revenues_per_day$day_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_day$revenues_if_no_campaign <- rep(revenues_per_day$revenues_actual[1], nrow(revenues_per_day))
for(r in 2:nrow(revenues_per_day)) {
if(revenues_per_day$day_end[r] <= campaign_start) {
revenues_per_day$revenues_if_no_campaign[r] <- revenues_per_day$revenues_actual[r]
} else {
revenues_per_day$revenues_if_no_campaign[r] <- min(revenues_per_day$revenues_if_no_campaign[r-1]*revenues_per_day$revenues_benchmark[r]/revenues_per_day$revenues_benchmark[r-1],
revenues_per_day$revenues_actual[r])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_day$revenues_benchmark2 <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
if(revenues_per_day$day_end[r] <= campaign_start) {
revenues_per_day$revenues_benchmark2[r] <- revenues_per_day$revenues_actual[r]
} else {
revenues_per_day$revenues_benchmark2[r] <- sum(revenues_per_hour$revenues_benchmark2[(r*24-23):(r*24)])
}
}
# Add time since campaign column
revenues_per_day$days_since_campaign <- time_length((revenues_per_day$day_start - as.POSIXct(campaign_start)), "days")
# Add non-NGU total revenues
revenues_per_day$revenues_actual_nonNGU <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_actual_nonNGU[r] <- sum(revenues_campaign_nonNGUs$net_value[revenues_campaign_nonNGUs$datetime > revenues_per_day$day_start[r] & revenues_campaign_nonNGUs$datetime <= revenues_per_day$day_end[r]])
}
# Add revenues for reawakens =  non-NGU_revenues - benchmark revenues (assumes organic NGU revenues are negligible!!)   ### prev doing revenues_actual_nonNGU - (nonNGU active users - reawaken AUs) * RPAU_benchmark
revenues_per_day$revenues_reawakens <- pmax(0, revenues_per_day$revenues_actual_nonNGU - revenues_per_day$revenues_benchmark2)
# Add revenues for NGU uplift users (assumes NGU for uplift users the same as organic NGU - maybe not realistic but organic NGUs only small % of total NGUs)
revenues_per_day$revenues_NGU_uplift <- pmax(0, (revenues_per_day$revenues_actual-revenues_per_day$revenues_actual_nonNGU) * (NGU_per_day$NGU_actual - NGU_per_day$NGU_benchmark2)/NGU_per_day$NGU_actual )
# Add revenues from marketing tracked installs
revenues_per_day$revenues_marketing_tracked_installs <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_marketing_tracked_installs[r] <- sum(revenues_campaign_marketing_tracked_installs$net_value[revenues_campaign_marketing_tracked_installs$datetime > revenues_per_day$day_start[r] & revenues_campaign_marketing_tracked_installs$datetime <= revenues_per_day$day_end[r]])
}
## QUARTER DAY ANALYSIS
# Separate analysis period into quarter days
revenues_per_q_day <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-6*60*60), by = 6*60*60))
colnames(revenues_per_q_day) <- "q_day_start"
revenues_per_q_day$q_day_end <- revenues_per_q_day$q_day_start+6*60*60
# Add benchmark revenues per q_day
revenues_per_q_day$revenues_benchmark <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
revenues_per_q_day$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_q_day$q_day_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_q_day$q_day_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_q_day$revenues_benchmark[revenues_per_q_day$revenues_benchmark==0] <- 0.1
# Add actual revenues per q_day
revenues_per_q_day$revenues_actual <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
revenues_per_q_day$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_q_day$q_day_start[r] & revenues_campaign$datetime <= revenues_per_q_day$q_day_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_q_day$revenues_if_no_campaign <- rep(revenues_per_q_day$revenues_actual[1], nrow(revenues_per_q_day))
for(r in 2:nrow(revenues_per_q_day)) {
if(revenues_per_q_day$q_day_end[min(r+1,nrow(revenues_per_q_day))] <= campaign_start) {
revenues_per_q_day$revenues_if_no_campaign[r] <- revenues_per_q_day$revenues_actual[r]
} else {
revenues_per_q_day$revenues_if_no_campaign[r] <- sum(revenues_per_hour$revenues_if_no_campaign[(r*6-5):(r*6)])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_q_day$revenues_benchmark2 <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
if(revenues_per_q_day$q_day_end[min(r+1,nrow(revenues_per_q_day))] <= campaign_start) {
revenues_per_q_day$revenues_benchmark2[r] <- revenues_per_q_day$revenues_actual[r]
} else {
revenues_per_q_day$revenues_benchmark2[r] <- sum(revenues_per_hour$revenues_benchmark2[(r*6-5):(r*6)])
}
}
# Add time since campaign column
revenues_per_q_day$days_since_campaign <- time_length((revenues_per_q_day$q_day_start - as.POSIXct(campaign_start)), "days")
# OUTPUT ------------------------------------------------------------------------------------------------------------------------
### Plot benchmark vs actual revenues
# For hourly analysis (Youtube)
revenues_plot_per_hour <- ggplot(data = revenues_per_hour) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (hours)") +
ylab("revenues") +
ylim(0, max(revenues_per_hour$revenues_actual, revenues_per_hour$revenues_actual)) +
scale_x_continuous(breaks = seq(as.integer(min(revenues_per_hour$time_since_campaign)), as.integer(max(revenues_per_hour$time_since_campaign))+1, 24)) +
scale_colour_manual("",
breaks = c("Actual", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
# For daily analysis (TV)
revenues_plot_per_day <- ggplot(data = revenues_per_day) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_actual-revenues_per_day$revenues_reawakens, colour = "Actual (excl. reawakens)"), linetype="dashed", size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (days)") +
ylab("revenues") +
ylim(0, max(revenues_per_day$revenues_actual, revenues_per_day$revenues_actual)) +
scale_colour_manual("",
breaks = c("Actual", "Actual (excl. reawakens)", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Actual (excl. reawakens)"="seagreen2", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
# For quarter day analysis
revenues_plot_per_q_day <- ggplot(data = revenues_per_q_day) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (days)") +
ylab("revenues") +
ylim(0, max(revenues_per_q_day$revenues_actual, revenues_per_q_day$revenues_actual)) +
scale_colour_manual("",
breaks = c("Actual", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
### Table of uplift in revenues
# table of comparison between benchmarks and actual revenues
revenues_table <- cbind(revenues_per_day[,c(1,2)],
paste0(wday(revenues_per_day$day_start+1, label = TRUE), "/", wday(revenues_per_day$day_end-1, label = TRUE)),
round(revenues_per_day[,4]), round(revenues_per_day[,5]),
round(pmax(revenues_per_day[,4]-revenues_per_day[,5],0)),
round(revenues_per_day[,6]),
round(pmax(revenues_per_day[,4]-revenues_per_day[,6],0)),
round(revenues_per_day$revenues_NGU_uplift),
round(revenues_per_day$revenues_reawakens),
round(revenues_per_day$revenues_marketing_tracked_installs, 2))[AUs_per_day$days_since_campaign>=0,]
colnames(revenues_table) <- c("day_start", "day_end", "weekday", "revenues_actual", "revenues_benchmark(other_countries)", "uplift(cf_other_countries)",
"revenues_benchmark(earlier_period)", "[uplift(cf_earlier_period)", "= NGU uplift", "+ reawakens]", "marketing tracked revenues")
### ARPU
ARPU_table <- cbind(
# ARPU_NGU_uplift_only
round(as.numeric(revenues_table$`= NGU uplift`/AUs_table$`= NGU uplift`),3),
# ARPU marketing tracked NGUs only
round(as.numeric(revenues_table$`marketing tracked revenues`/AUs_table$`marketing tracked AUs`),3),
# ARPU_reawakens
round(as.numeric(revenues_table$`+ reawakens]`/AUs_table$`+ reawakens]`),3),
# ARPU_all_"organic"_users
round(as.numeric(revenues_table$revenues_actual/AUs_table$AUs_actual),3),
# ARPU_all_users
rep("see SPBO", nrow(revenues_table))
)
colnames(ARPU_table) <- c("ARPU_NGU_uplift", "ARPU_marketing_tracked_installs", "ARPU_reawakens", "ARPU_'organic'_users", "ARPU_all_users")
### RPI table
campaign_RPI_table <- cbind(
# day start, day end and weekday
revenues_table$day_start, revenues_table$day_end, as.character(revenues_table$weekday),
# cumulative NGUs
sapply(1:analysis_period, function(d) sum(NGU_per_day$NGU_actual[NGU_per_day$days_since_campaign>=0][1:d])),
# cumulative revenues
round(
sapply(1:analysis_period, function(d) sum((revenues_per_day$revenues_actual
- revenues_per_day$revenues_actual_nonNGU
)[revenues_per_day$days_since_campaign>=0][1:d]))
),
# RPI
round(
sapply(1:analysis_period, function(d) sum((revenues_per_day$revenues_actual
- revenues_per_day$revenues_actual_nonNGU
)[revenues_per_day$days_since_campaign>=0][1:d]))
/sapply(1:analysis_period, function(d) sum(NGU_per_day$NGU_actual[NGU_per_day$days_since_campaign>=0][1:d]))
, 3)
)
colnames(campaign_RPI_table) <- c("day_start", "day_end", "weekday", "cumulative NGUs", "cumulative revenues", "RPI")
NGU_plot_per_day
NGU_plot_per_hour
spark_home<-"/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7"
Sys.setenv(SPARK_HOME = spark_home)
spark_bin <- paste0(spark_home, '/bin')
Sys.setenv(PATH = paste(Sys.getenv(c('PATH')), spark_bin, sep=':'))
hadoop_home <- "/usr/lib/hadoop/"
postgresql_drv <- "/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/postgresql-9.4.1212.jar"
if(!file.exists(postgresql_drv)){
system('curl "https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar" -o "~/Desktop/projects/payer_again/spark_scripts/local_test/"')
}
spark_link <- "local[*]"
spark_bin
library(SparkR, lib.loc = "/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7/R/lib/")
Sys.setenv('SPARKR_SUBMIT_ARGS'='"--packages" "com.databricks:spark-csv_2.10:1.3.0" "sparkr-shell"')
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
spark_home<-"/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7"
Sys.setenv(SPARK_HOME = spark_home)
spark_bin <- paste0(spark_home, '/bin')
Sys.setenv(PATH = paste(Sys.getenv(c('PATH')), spark_bin, sep=':'))
hadoop_home <- "/usr/lib/hadoop/"
Sys.setenv(HADOOP_HOME = hadoop_home) # hadoop-common missing on Windows
postgresql_drv <- "/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/postgresql-9.4.1212.jar"
if(!file.exists(postgresql_drv)){
system('curl "https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar" -o "~/Desktop/projects/payer_again/spark_scripts/local_test/"')
}
spark_link <- "local[*]"
library(SparkR, lib.loc = "/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7/R/lib/")
Sys.setenv('SPARKR_SUBMIT_ARGS'='"--packages" "com.databricks:spark-csv_2.10:1.3.0" "sparkr-shell"')
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sparkR.version()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
setwd("~/Desktop/sp-analytics-machine-learning-develop-master/payer_again/spark_scripts/local_test/further_testing")
print(paste(base::date(), " Starting Spark Payer Again DC Training"))
options(java.parameters = "-Xmx30g")
refreshDataTables_inredshift<-TRUE
source("../src/loadPackages.R")
source("../src/set_spark_session.R")
source("../src/test_accuracies.R")
payer_again_data <- readRDS("./data/training_data2016-10-01.rds")
payer_again_data["spending_momentum"] = payer_again_data$total_spend_last7days/payer_again_data$spend_per_week
payer_again_data["transactions_momentum"] = payer_again_data$transaction_count_last7days/payer_again_data$transactions_per_week
payer_again_data["sessions_momentum"] = payer_again_data$total_sessions_last2days*3.5/payer_again_data$sessions_per_week
payer_again_data["videoads_momentum"] = ifelse(payer_again_data$videoads_per_week==0, 0, payer_again_data$total_videoads_last7days/payer_again_data$videoads_per_week)
payer_again_test_date1 <- readRDS("./data/test_data2016-08-01.rds")
payer_again_test_date1["spending_momentum"] = payer_again_test_date1$total_spend_last7days/payer_again_test_date1$spend_per_week
payer_again_test_date1["transactions_momentum"] = payer_again_test_date1$transaction_count_last7days/payer_again_test_date1$transactions_per_week
payer_again_test_date1["sessions_momentum"] = payer_again_test_date1$total_sessions_last2days*3.5/payer_again_test_date1$sessions_per_week
payer_again_test_date1["videoads_momentum"] = ifelse(payer_again_test_date1$videoads_per_week==0, 0, payer_again_test_date1$total_videoads_last7days/payer_again_test_date1$videoads_per_week)
payer_again_test_date2 <- readRDS("./data/test_data2016-09-01.rds")
payer_again_test_date2["spending_momentum"] = payer_again_test_date2$total_spend_last7days/payer_again_test_date2$spend_per_week
payer_again_test_date2["transactions_momentum"] = payer_again_test_date2$transaction_count_last7days/payer_again_test_date2$transactions_per_week
payer_again_test_date2["sessions_momentum"] = payer_again_test_date2$total_sessions_last2days*3.5/payer_again_test_date2$sessions_per_week
payer_again_test_date2["videoads_momentum"] = ifelse(payer_again_test_date2$videoads_per_week==0, 0, payer_again_test_date2$total_videoads_last7days/payer_again_test_date2$videoads_per_week)
payer_again_test_date3 <- readRDS("./data/test_data2016-12-15.rds")
payer_again_test_date3["spending_momentum"] = payer_again_test_date3$total_spend_last7days/payer_again_test_date3$spend_per_week
payer_again_test_date3["transactions_momentum"] = payer_again_test_date3$transaction_count_last7days/payer_again_test_date3$transactions_per_week
payer_again_test_date3["sessions_momentum"] = payer_again_test_date3$total_sessions_last2days*3.5/payer_again_test_date3$sessions_per_week
payer_again_test_date3["videoads_momentum"] = ifelse(payer_again_test_date3$videoads_per_week==0, 0, payer_again_test_date3$total_videoads_last7days/payer_again_test_date3$videoads_per_week)
payer_again_data_train <- createDataFrame(payer_again_data[payer_again_data$days_since_register>0,])
payer_again_data_test1 <- createDataFrame(payer_again_test_date1[payer_again_test_date1$days_since_register>0,])
payer_again_data_test2 <- createDataFrame(payer_again_test_date2[payer_again_test_date2$days_since_register>0,])
payer_again_data_test3 <- createDataFrame(payer_again_test_date3[payer_again_test_date3$days_since_register>0,])
gbt_model <- read.ml("~/Desktop/sp-analytics-machine-learning-develop-master/payer_again/spark_scripts/local_test/further_testing/model/gbt_model")
gbt_summary <- summary(gbt_model)
gbt_feature_importance <- gbt_summary$featureImportances
gbt_feature_importance
[0, 3, 2]
gbt_feature_importance[3:5]
strsplit(gbt_feature_importance)
strsplit(gbt_feature_importance, 3, 5)
gbt_feature_importance
strsplit(gbt_feature_importance, '[')
strsplit(gbt_feature_importance, '[', ']')
strsplit(gbt_feature_importance, [, )
#rf_model <- read.ml(object = rf_android, path = paste0("s3://sp-dataproduct/payer_again_dc/preproduction/current_model/rf_model"))
#print(paste(base::date(), " Predictions with Random Forest"))
#pred_rf <- predict(rf_model, payer_again_data_test)
#print(paste(base::date(), " Predictions with GBT"))
pred1_gbt <- predict(gbt_model, payer_again_data_test1)
pred2_gbt <- predict(gbt_model, payer_again_data_test2)
pred3_gbt <- predict(gbt_model, payer_again_data_test3)
# Collect the data into base R tables
print(paste(base::date(), " Test the accuracies"))
payer_again_predictions1 <- collect(pred1_gbt)
gbt_feature_importance
strsplit(gbt_feature_importance, ], )
strsplit(gbt_feature_importance, 3, )
strsplit(gbt_feature_importance, 5, )
gbt_feature_importance
substring(gbt_feature_importance, 5, 120)
substring(gbt_feature_importance, 5, 110)
substring(gbt_feature_importance, 5, 106)
substring(gbt_feature_importance, 6, 105)
paste0('(',substring(gbt_feature_importance, 6, 105),')')
paste0('c(',substring(gbt_feature_importance, 6, 105),')')
substring(gbt_feature_importance, 108, 500)
substring(gbt_feature_importance, 108, 900)
substring(gbt_feature_importance, 108, -1)
substring(gbt_feature_importance, 108)
substring(gbt_feature_importance, 108, 880)
substring(gbt_feature_importance, 108, 800)
substring(gbt_feature_importance, 108, 850)
substring(gbt_feature_importance, 108, 867)
substring(gbt_feature_importance, 108, 875)
substring(gbt_feature_importance, 108, 870)
substring(gbt_feature_importance, 108, 871)
substring(gbt_feature_importance, 108, 872)
substring(gbt_feature_importance, 108, 873)
substring(gbt_feature_importance, 108, 874)
substring(gbt_feature_importance, 108, 873)
cbind("feature_number" = paste0('c(',substring(gbt_feature_importance, 6, 105),')'), "importance" = paste0('c(',substring(gbt_feature_importance, 108, 873),')'))
cbind("feature_number" = paste0('c(',substring(gbt_feature_importance, 6, 105),')'), "importance" = paste0('c(',substring(gbt_feature_importance, 109, 873),')'))
paste0('c(',substring(gbt_feature_importance, 109, 873),')')
cbind(
"feature_number" = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,31,34,35,36,37,38,39),
"importance" = c(0.04883127935945804,0.06732157256264906,0.016813538247693216,7.989199974379327E-4,0.03597531394949357,0.005338963506235719,0.06102499613380098,0.00459166066765472,0.042888790213505466,0.16791508921877857,0.13206885609433294,0.0077986280789364894,0.005312958006685409,0.03492757338611123,0.004922199134272447,0.0054265502017206545,0.011675940892478025,0.028161382081829417,1.3117703895797553E-4,0.00540198832599538,0.013738971779308584,0.014815575860759937,0.07475208051306549,0.01971443024855162,0.07074721746534009,0.003130457420535787,0.017461593303342647,0.00806410707695552,3.6507535536367357E-4,7.071378216968543E-4,5.657462875180798E-4,0.022150052252546393,0.017706589752463683,0.0024617430979012606,0.0038119495428423763,0.033288582116503,0.00919131300727796)
)
gbt_summary$numFeatures
gbt_summary$formula
gbt_summary$features
gbt_feature_importance_table <- cbind(
"feature_number" = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,31,34,35,36,37,38,39),
"importance" = c(0.04883127935945804,0.06732157256264906,0.016813538247693216,7.989199974379327E-4,0.03597531394949357,0.005338963506235719,0.06102499613380098,0.00459166066765472,0.042888790213505466,0.16791508921877857,0.13206885609433294,0.0077986280789364894,0.005312958006685409,0.03492757338611123,0.004922199134272447,0.0054265502017206545,0.011675940892478025,0.028161382081829417,1.3117703895797553E-4,0.00540198832599538,0.013738971779308584,0.014815575860759937,0.07475208051306549,0.01971443024855162,0.07074721746534009,0.003130457420535787,0.017461593303342647,0.00806410707695552,3.6507535536367357E-4,7.071378216968543E-4,5.657462875180798E-4,0.022150052252546393,0.017706589752463683,0.0024617430979012606,0.0038119495428423763,0.033288582116503,0.00919131300727796),
"feature" = 0
)
View(gbt_feature_importance_table)
gbt_feature_importance_table['feature_number']
gbt_feature_importance_table$feature_number
gbt_feature_importance_table[feature_number]
gbt_feature_importance_table['feature_number']
gbt_feature_importance_table[,'feature_number']
gbt_summary$features
gbt_summary$features[3]
gbt_feature_importance_table[2,'feature_number']
gbt_feature_importance_table[9,'feature_number']
gbt_summary$features[gbt_feature_importance_table[3,'feature_number']+1]
gbt_summary$features[gbt_feature_importance_table[5,'feature_number']+1]
gbt_summary$features
gbt_feature_importance_table[5,'feature'] <- gbt_summary$features[gbt_feature_importance_table[5,'feature_number']+1]
gbt_feature_importance_table <- cbind(
"feature_number" = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,31,34,35,36,37,38,39),
"importance" = c(0.04883127935945804,0.06732157256264906,0.016813538247693216,7.989199974379327E-4,0.03597531394949357,0.005338963506235719,0.06102499613380098,0.00459166066765472,0.042888790213505466,0.16791508921877857,0.13206885609433294,0.0077986280789364894,0.005312958006685409,0.03492757338611123,0.004922199134272447,0.0054265502017206545,0.011675940892478025,0.028161382081829417,1.3117703895797553E-4,0.00540198832599538,0.013738971779308584,0.014815575860759937,0.07475208051306549,0.01971443024855162,0.07074721746534009,0.003130457420535787,0.017461593303342647,0.00806410707695552,3.6507535536367357E-4,7.071378216968543E-4,5.657462875180798E-4,0.022150052252546393,0.017706589752463683,0.0024617430979012606,0.0038119495428423763,0.033288582116503,0.00919131300727796),
"feature" = 0
)
gbt_feature_importance_table[5,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[5,'feature_number']+1]]
for(r in NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r+1,'feature'] <- gbt_summary$features[gbt_feature_importance_table[r,'feature_number']+1]
}
for(r in NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r+1,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[r,'feature_number']+1]]
}
for(r in 1:NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r+1,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[r,'feature_number']+1]]
}
g
for(r in 1:NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r+1,'feature'] <- gbt_summary$features[[(gbt_feature_importance_table[r,'feature_number']+1)]]
}
gbt_feature_importance_table[5,'feature_number']
gbt_feature_importance_table[5,'feature_number']+1
gbt_feature_importance_table[5,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[5,'feature_number']+1]]
gbt_feature_importance_table <- cbind(
"feature_number" = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,31,34,35,36,37,38,39),
"importance" = c(0.04883127935945804,0.06732157256264906,0.016813538247693216,7.989199974379327E-4,0.03597531394949357,0.005338963506235719,0.06102499613380098,0.00459166066765472,0.042888790213505466,0.16791508921877857,0.13206885609433294,0.0077986280789364894,0.005312958006685409,0.03492757338611123,0.004922199134272447,0.0054265502017206545,0.011675940892478025,0.028161382081829417,1.3117703895797553E-4,0.00540198832599538,0.013738971779308584,0.014815575860759937,0.07475208051306549,0.01971443024855162,0.07074721746534009,0.003130457420535787,0.017461593303342647,0.00806410707695552,3.6507535536367357E-4,7.071378216968543E-4,5.657462875180798E-4,0.022150052252546393,0.017706589752463683,0.0024617430979012606,0.0038119495428423763,0.033288582116503,0.00919131300727796),
"feature" = 0
)
gbt_feature_importance_table[5,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[5,'feature_number']+1]]
gbt_feature_importance_table[5,'feature_number']+1
gbt_feature_importance_table <- cbind(
"feature_number" = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,31,34,35,36,37,38,39),
"importance" = c(0.04883127935945804,0.06732157256264906,0.016813538247693216,7.989199974379327E-4,0.03597531394949357,0.005338963506235719,0.06102499613380098,0.00459166066765472,0.042888790213505466,0.16791508921877857,0.13206885609433294,0.0077986280789364894,0.005312958006685409,0.03492757338611123,0.004922199134272447,0.0054265502017206545,0.011675940892478025,0.028161382081829417,1.3117703895797553E-4,0.00540198832599538,0.013738971779308584,0.014815575860759937,0.07475208051306549,0.01971443024855162,0.07074721746534009,0.003130457420535787,0.017461593303342647,0.00806410707695552,3.6507535536367357E-4,7.071378216968543E-4,5.657462875180798E-4,0.022150052252546393,0.017706589752463683,0.0024617430979012606,0.0038119495428423763,0.033288582116503,0.00919131300727796),
"feature" = 0
)
gbt_feature_importance_table[5,'feature_number']+1
gbt_feature_importance_table[5,'feature'] <- gbt_summary$features[[gbt_feature_importance_table[5,'feature_number']+1]]
gbt_feature_importance_table[5,'feature_number']+1
gbt_feature_importance_table[5,'feature_number']+1
as.integer(gbt_feature_importance_table[5,'feature_number'])+1
for(r in 1:NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r+1,'feature'] <- gbt_summary$features[[as.integer(gbt_feature_importance_table[r,'feature_number'])+1]]
}
for(r in 1:NROW(gbt_feature_importance_table)){
gbt_feature_importance_table[r,'feature'] <- gbt_summary$features[[as.integer(gbt_feature_importance_table[r,'feature_number'])+1]]
}
typeof(gbt_feature_importance_table)
order(gbt_feature_importance_table[,'importance'])
order(-gbt_feature_importance_table[,'importance'])
order(1-gbt_feature_importance_table[,'importance'])
order(gbt_feature_importance_table[,'importance'])
gbt_feature_importance_table[,'importance']
-gbt_feature_importance_table[,'importance']
-as.integer(gbt_feature_importance_table[,'importance'])
-as.double(gbt_feature_importance_table[,'importance'])
order(-as.double(gbt_feature_importance_table[,'importance']))
gbt_feature_importance_table[order(-as.double(gbt_feature_importance_table[,'importance'])),]
gbt_feature_importance_table <- gbt_feature_importance_table[order(-as.double(gbt_feature_importance_table[,'importance'])),]
View(payer_again_data)
