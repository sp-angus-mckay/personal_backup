revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+10:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+10:00"] + 10*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+10:30"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+10:30"] + 10*3600 + 3600*0.5
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+11:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+11:00"] + 11*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+12:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "+12:00"] + 12*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-01:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-01:00"] - 3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-02:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-02:00"] - 2*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-03:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-03:00"] - 3*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-03:30"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-03:30"] - 3*3600 + 3600*0.5
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-04:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-04:00"] - 4*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-05:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-05:00"] - 5*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-06:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-06:00"] - 6*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-07:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-07:00"] - 7*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-08:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-08:00"] - 8*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-09:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-09:00"] - 9*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-10:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-10:00"] - 10*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-11:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-11:00"] - 11*3600
revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-12:00"] <- revenues_benchmark$real_date[revenues_benchmark$ip_timezone == "-12:00"] - 12*3600
revenues_benchmark$wday <- as.POSIXlt(revenues_benchmark$real_date)$wday
# DOWNLOAD BENCHMARK 2 DATA ----------------------------------------------------------------------------------------
cat("DOWNLOAD REVENUES DATA FOR OTHER COUNTRIES")
cat("\n")
benchmark2_query_revenues <- paste( "SELECT convert_timezone('UTC','Europe/Madrid', t_transaction.datetime) as datetime, t_transaction.ip_timezone, COALESCE(t_transaction.amount_gross*0.7, 0) AS net_value
FROM ",schema,".t_transaction
LEFT JOIN ",schema,".log_session_start
ON t_transaction.session_id = log_session_start.session_id
AND t_transaction.user_id = log_session_start.user_id
LEFT JOIN ",schema,".t_user
ON t_transaction.user_id = t_user.user_id
WHERE t_transaction.datetime >= '", bm2_query_start_date, "'
AND t_transaction.datetime <= '", bm2_query_end_date, "'
--AND t_user.user_category <> 'hacker' AND t_user.user_category = 'player'
AND (t_user.register_source is NULL or lower(t_user.register_source) like '%organic%' or t_user.register_source = '')
AND (t_user.migrate_date_orphaned is null or datediff(s, t_user.date_register, t_user.migrate_date_orphaned) > 86400)
AND (t_transaction.offer != 'earncash' OR t_transaction.offer IS NULL)
AND t_transaction.platform = '", platform, "'
AND t_transaction.ip_country = '", country,"'
AND (t_user.is_tester is null or t_user.is_tester != 'true')
AND t_user.user_category <> 'bot'
AND date_add('d', -1, '", bm2_query_start_date, "') <= log_session_start.datetime
AND log_session_start.datetime <= '", bm2_query_end_date, "'", sep = "")
revenues_benchmark2 <- dbGetQuery(spdb, benchmark2_query_revenues)
# Add a column with the real date of the country of install, the weekday and hour
revenues_benchmark2$real_date <- revenues_benchmark2$datetime
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+01:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+01:00"] + 3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+02:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+02:00"] + 2*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+03:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+03:00"] + 3*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+04:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+04:00"] + 4*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+05:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+05:00"] + 5*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+06:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+06:00"] + 6*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+07:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+07:00"] + 7*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+08:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+08:00"] + 8*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:00"] + 9*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+09:30"] + 9*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:00"] + 10*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+10:30"] + 10*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+11:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+11:00"] + 11*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+12:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "+12:00"] + 12*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-01:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-01:00"] - 3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-02:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-02:00"] - 2*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:00"] - 3*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:30"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-03:30"] - 3*3600 + 3600*0.5
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-04:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-04:00"] - 4*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-05:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-05:00"] - 5*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-06:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-06:00"] - 6*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-07:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-07:00"] - 7*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-08:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-08:00"] - 8*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-09:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-09:00"] - 9*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-10:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-10:00"] - 10*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-11:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-11:00"] - 11*3600
revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-12:00"] <- revenues_benchmark2$real_date[revenues_benchmark2$ip_timezone == "-12:00"] - 12*3600
# Add the weekday and hour based on Madrid time to be consistent with NGU analysis
revenues_benchmark2$wday <- as.POSIXlt(revenues_benchmark2$datetime)$wday
revenues_benchmark2$hour <- unlist(strsplit(as.character(revenues_benchmark2$datetime), " "))[seq(2,length(revenues_benchmark2$datetime)*2,by = 2)]
revenues_benchmark2$hour <- as.character(revenues_benchmark2$hour) # Convert factors to characters
### Add revenues per hour to bm2 data
# Adding the average revenues for each hour period
bm2_unique_hours_periods$Total_revenues <- rep(0, nrow(bm2_unique_hours_periods))
for(r in 1:nrow(bm2_unique_hours_periods)) {
bm2_unique_hours_periods$Total_revenues[r] <- sum(revenues_benchmark2$net_value[as.POSIXlt(revenues_benchmark2$datetime)$hour==bm2_unique_hours_periods$hour[r] &
as.POSIXlt(revenues_benchmark2$datetime)$wday==bm2_unique_hours_periods$day[r]])
}
# Calculating average revenues per hour and per minute for each hour period
bm2_unique_hours_periods$Avg_revenues_per_HOUR <- bm2_unique_hours_periods$Total_revenues/bm2_unique_hours_periods$occurences
bm2_unique_hours_periods$Avg_revenues_per_MINUTE <- bm2_unique_hours_periods$Avg_revenues_per_HOUR/60
# DOWNLOAD CAMPAIGN MARKETING TRACKED DATA ----------------------------------------------------------------------------------------
cat("DOWNLOAD MARKETING TRACKED USER REVENUES DATA FROM REDSHIFT")
cat("\n")
campaign_query_marketing_tracked_user_revenues <- paste( "SELECT convert_timezone('UTC','Europe/Madrid', t_transaction.datetime) as datetime, t_transaction.ip_timezone, COALESCE(t_transaction.amount_gross*0.7, 0) AS net_value
FROM ",schema,".t_transaction
LEFT JOIN ",schema,".log_session_start
ON t_transaction.session_id = log_session_start.session_id
AND t_transaction.user_id = log_session_start.user_id
LEFT JOIN ",schema,".t_user
ON t_transaction.user_id = t_user.user_id
WHERE t_transaction.datetime >= '", query_start_date, "'
AND t_transaction.datetime <= '", query_end_date, "'
AND lower(t_user.register_source) in ", marketing_tracker_source, "
AND (t_transaction.offer != 'earncash' OR t_transaction.offer IS NULL)
AND t_transaction.platform = '", platform, "'
AND t_transaction.ip_country = '", country,"'
AND date_add('d', -1, '", query_start_date, "') <= log_session_start.datetime
AND log_session_start.datetime <= '", query_end_date, "'", sep = "")
revenues_campaign_marketing_tracked_installs <- dbGetQuery(spdb, campaign_query_marketing_tracked_user_revenues)
# Add a column with the real date of the country of install and the weekday
revenues_campaign_marketing_tracked_installs$real_date <- revenues_campaign_marketing_tracked_installs$datetime
# ATTRIBUTION ANALYSIS --------------------------------------------------------------------------------------------------
cat("ATTRIBUTION ANALYSIS")
cat("\n")
## PER HOUR ANALYSIS
# Separate analysis period into hours
revenues_per_hour <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-60*60), by = "hour"))
colnames(revenues_per_hour) <- "hour_start"
revenues_per_hour$hour_end <- revenues_per_hour$hour_start+60*60
# Add benchmark revenues per hour
revenues_per_hour$revenues_benchmark <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
revenues_per_hour$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_hour$hour_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_hour$hour_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_hour$revenues_benchmark[revenues_per_hour$revenues_benchmark==0] <- 0.1
# Add actual revenues per hour
revenues_per_hour$revenues_actual <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
revenues_per_hour$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_hour$hour_start[r] & revenues_campaign$datetime <= revenues_per_hour$hour_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_hour$revenues_if_no_campaign <- rep(revenues_per_hour$revenues_actual[1], nrow(revenues_per_hour))
for(r in 2:nrow(revenues_per_hour)) {
if(revenues_per_hour$hour_end[min(r+1,nrow(revenues_per_hour))] <= campaign_start) {
revenues_per_hour$revenues_if_no_campaign[r] <- revenues_per_hour$revenues_actual[r]
} else {
revenues_per_hour$revenues_if_no_campaign[r] <- min(revenues_per_hour$revenues_actual[r],
revenues_per_hour$revenues_if_no_campaign[r-1]*revenues_per_hour$revenues_benchmark[r]/revenues_per_hour$revenues_benchmark[r-1])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_hour$revenues_benchmark2 <- rep(0, nrow(revenues_per_hour))
for(r in 1:nrow(revenues_per_hour)) {
if(revenues_per_hour$hour_end[min(r+1,nrow(revenues_per_hour))] <= campaign_start) {
revenues_per_hour$revenues_benchmark2[r] <- revenues_per_hour$revenues_actual[r]
} else {
revenues_per_hour$revenues_benchmark2[r] <- bm2_unique_hours_periods$Avg_revenues_per_HOUR[bm2_unique_hours_periods$hour==as.POSIXlt(revenues_per_hour$hour_start[r])$hour & bm2_unique_hours_periods$day==as.POSIXlt(revenues_per_hour$hour_start[r])$wday]
}
}
# Add time since campaign column
revenues_per_hour$time_since_campaign <- time_length((revenues_per_hour$hour_start - as.POSIXct(campaign_start)), "hours")
## PER DAY ANALYSIS
# Separate analysis period into days
revenues_per_day <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-24*60*60), by = "day"))
colnames(revenues_per_day) <- "day_start"
revenues_per_day$day_end <- revenues_per_day$day_start+24*60*60
# Add benchmark revenues per day
revenues_per_day$revenues_benchmark <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_day$day_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_day$day_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_day$revenues_benchmark[revenues_per_day$revenues_benchmark==0] <- 0.1
# Add actual revenues per day
revenues_per_day$revenues_actual <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_day$day_start[r] & revenues_campaign$datetime <= revenues_per_day$day_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_day$revenues_if_no_campaign <- rep(revenues_per_day$revenues_actual[1], nrow(revenues_per_day))
for(r in 2:nrow(revenues_per_day)) {
if(revenues_per_day$day_end[r] <= campaign_start) {
revenues_per_day$revenues_if_no_campaign[r] <- revenues_per_day$revenues_actual[r]
} else {
revenues_per_day$revenues_if_no_campaign[r] <- min(revenues_per_day$revenues_if_no_campaign[r-1]*revenues_per_day$revenues_benchmark[r]/revenues_per_day$revenues_benchmark[r-1],
revenues_per_day$revenues_actual[r])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_day$revenues_benchmark2 <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
if(revenues_per_day$day_end[r] <= campaign_start) {
revenues_per_day$revenues_benchmark2[r] <- revenues_per_day$revenues_actual[r]
} else {
revenues_per_day$revenues_benchmark2[r] <- sum(revenues_per_hour$revenues_benchmark2[(r*24-23):(r*24)])
}
}
# Add time since campaign column
revenues_per_day$days_since_campaign <- time_length((revenues_per_day$day_start - as.POSIXct(campaign_start)), "days")
# Add non-NGU total revenues
revenues_per_day$revenues_actual_nonNGU <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_actual_nonNGU[r] <- sum(revenues_campaign_nonNGUs$net_value[revenues_campaign_nonNGUs$datetime > revenues_per_day$day_start[r] & revenues_campaign_nonNGUs$datetime <= revenues_per_day$day_end[r]])
}
# Add revenues for reawakens =  non-NGU_revenues - benchmark revenues (assumes organic NGU revenues are negligible!!)   ### prev doing revenues_actual_nonNGU - (nonNGU active users - reawaken AUs) * RPAU_benchmark
revenues_per_day$revenues_reawakens <- pmax(0, revenues_per_day$revenues_actual_nonNGU - revenues_per_day$revenues_benchmark2)
# Add revenues for NGU uplift users (assumes NGU for uplift users the same as organic NGU - maybe not realistic but organic NGUs only small % of total NGUs)
revenues_per_day$revenues_NGU_uplift <- pmax(0, (revenues_per_day$revenues_actual-revenues_per_day$revenues_actual_nonNGU) * (NGU_per_day$NGU_actual - NGU_per_day$NGU_benchmark2)/NGU_per_day$NGU_actual )
# Add revenues from marketing tracked installs
revenues_per_day$revenues_marketing_tracked_installs <- rep(0, nrow(revenues_per_day))
for(r in 1:nrow(revenues_per_day)) {
revenues_per_day$revenues_marketing_tracked_installs[r] <- sum(revenues_campaign_marketing_tracked_installs$net_value[revenues_campaign_marketing_tracked_installs$datetime > revenues_per_day$day_start[r] & revenues_campaign_marketing_tracked_installs$datetime <= revenues_per_day$day_end[r]])
}
## QUARTER DAY ANALYSIS
# Separate analysis period into quarter days
revenues_per_q_day <- as.data.frame(seq(from = as.POSIXct(analysis_start_date), to = as.POSIXct(analysis_end_date-6*60*60), by = 6*60*60))
colnames(revenues_per_q_day) <- "q_day_start"
revenues_per_q_day$q_day_end <- revenues_per_q_day$q_day_start+6*60*60
# Add benchmark revenues per q_day
revenues_per_q_day$revenues_benchmark <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
revenues_per_q_day$revenues_benchmark[r] <- sum(revenues_benchmark$net_value[revenues_benchmark$real_date > (revenues_per_q_day$q_day_start[r]+NGU_campaign_avg_timezone*60*60)
& revenues_benchmark$real_date <= (revenues_per_q_day$q_day_end[r]+NGU_campaign_avg_timezone*60*60)])
}
# Replace any 0s with 0.1s in benchmark data so that benchmark calculation doesn't return 0s or errors (and it will end up at same result)
revenues_per_q_day$revenues_benchmark[revenues_per_q_day$revenues_benchmark==0] <- 0.1
# Add actual revenues per q_day
revenues_per_q_day$revenues_actual <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
revenues_per_q_day$revenues_actual[r] <- sum(revenues_campaign$net_value[revenues_campaign$datetime > revenues_per_q_day$q_day_start[r] & revenues_campaign$datetime <= revenues_per_q_day$q_day_end[r]])
}
# Add what would actually have happened if there had been no marketing campaign (according to benchmark)
revenues_per_q_day$revenues_if_no_campaign <- rep(revenues_per_q_day$revenues_actual[1], nrow(revenues_per_q_day))
for(r in 2:nrow(revenues_per_q_day)) {
if(revenues_per_q_day$q_day_end[min(r+1,nrow(revenues_per_q_day))] <= campaign_start) {
revenues_per_q_day$revenues_if_no_campaign[r] <- revenues_per_q_day$revenues_actual[r]
} else {
revenues_per_q_day$revenues_if_no_campaign[r] <- sum(revenues_per_hour$revenues_if_no_campaign[(r*6-5):(r*6)])
}
}
# Add in benchmark 2 column (based on same country over a pre campaign period)
revenues_per_q_day$revenues_benchmark2 <- rep(0, nrow(revenues_per_q_day))
for(r in 1:nrow(revenues_per_q_day)) {
if(revenues_per_q_day$q_day_end[min(r+1,nrow(revenues_per_q_day))] <= campaign_start) {
revenues_per_q_day$revenues_benchmark2[r] <- revenues_per_q_day$revenues_actual[r]
} else {
revenues_per_q_day$revenues_benchmark2[r] <- sum(revenues_per_hour$revenues_benchmark2[(r*6-5):(r*6)])
}
}
# Add time since campaign column
revenues_per_q_day$days_since_campaign <- time_length((revenues_per_q_day$q_day_start - as.POSIXct(campaign_start)), "days")
# OUTPUT ------------------------------------------------------------------------------------------------------------------------
### Plot benchmark vs actual revenues
# For hourly analysis (Youtube)
revenues_plot_per_hour <- ggplot(data = revenues_per_hour) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_hour$time_since_campaign, y = revenues_per_hour$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (hours)") +
ylab("revenues") +
ylim(0, max(revenues_per_hour$revenues_actual, revenues_per_hour$revenues_actual)) +
scale_x_continuous(breaks = seq(as.integer(min(revenues_per_hour$time_since_campaign)), as.integer(max(revenues_per_hour$time_since_campaign))+1, 24)) +
scale_colour_manual("",
breaks = c("Actual", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
# For daily analysis (TV)
revenues_plot_per_day <- ggplot(data = revenues_per_day) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_actual-revenues_per_day$revenues_reawakens, colour = "Actual (excl. reawakens)"), linetype="dashed", size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_day$days_since_campaign, y = revenues_per_day$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (days)") +
ylab("revenues") +
ylim(0, max(revenues_per_day$revenues_actual, revenues_per_day$revenues_actual)) +
scale_colour_manual("",
breaks = c("Actual", "Actual (excl. reawakens)", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Actual (excl. reawakens)"="seagreen2", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
# For quarter day analysis
revenues_plot_per_q_day <- ggplot(data = revenues_per_q_day) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_actual, colour = "Actual"), size = 0.7) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_if_no_campaign, colour = "Benchmark (other countries)"), size = 0.7) +
geom_line(aes(x = revenues_per_q_day$days_since_campaign, y = revenues_per_q_day$revenues_benchmark2, colour = "Benchmark (earlier period)"), size = 0.7) +
xlab("Time since campaign (days)") +
ylab("revenues") +
ylim(0, max(revenues_per_q_day$revenues_actual, revenues_per_q_day$revenues_actual)) +
scale_colour_manual("",
breaks = c("Actual", "Benchmark (other countries)", "Benchmark (earlier period)"),
values = c("Actual"="seagreen3", "Benchmark (other countries)"="orange", "Benchmark (earlier period)"="salmon")) +
theme(legend.position = "top", legend.background = element_rect(fill = "grey90"), legend.key = element_rect(fill = "grey90"),
plot.background = element_rect(fill = "grey90"),
panel.background = element_rect(fill = "grey90"),
panel.grid.major = element_line(colour = "grey75"),
panel.grid.minor = element_line(colour = "grey75"))
### Table of uplift in revenues
# table of comparison between benchmarks and actual revenues
revenues_table <- cbind(revenues_per_day[,c(1,2)],
paste0(wday(revenues_per_day$day_start+1, label = TRUE), "/", wday(revenues_per_day$day_end-1, label = TRUE)),
round(revenues_per_day[,4]), round(revenues_per_day[,5]),
round(pmax(revenues_per_day[,4]-revenues_per_day[,5],0)),
round(revenues_per_day[,6]),
round(pmax(revenues_per_day[,4]-revenues_per_day[,6],0)),
round(revenues_per_day$revenues_NGU_uplift),
round(revenues_per_day$revenues_reawakens),
round(revenues_per_day$revenues_marketing_tracked_installs, 2))[AUs_per_day$days_since_campaign>=0,]
colnames(revenues_table) <- c("day_start", "day_end", "weekday", "revenues_actual", "revenues_benchmark(other_countries)", "uplift(cf_other_countries)",
"revenues_benchmark(earlier_period)", "[uplift(cf_earlier_period)", "= NGU uplift", "+ reawakens]", "marketing tracked revenues")
### ARPU
ARPU_table <- cbind(
# ARPU_NGU_uplift_only
round(as.numeric(revenues_table$`= NGU uplift`/AUs_table$`= NGU uplift`),3),
# ARPU marketing tracked NGUs only
round(as.numeric(revenues_table$`marketing tracked revenues`/AUs_table$`marketing tracked AUs`),3),
# ARPU_reawakens
round(as.numeric(revenues_table$`+ reawakens]`/AUs_table$`+ reawakens]`),3),
# ARPU_all_"organic"_users
round(as.numeric(revenues_table$revenues_actual/AUs_table$AUs_actual),3),
# ARPU_all_users
rep("see SPBO", nrow(revenues_table))
)
colnames(ARPU_table) <- c("ARPU_NGU_uplift", "ARPU_marketing_tracked_installs", "ARPU_reawakens", "ARPU_'organic'_users", "ARPU_all_users")
### RPI table
campaign_RPI_table <- cbind(
# day start, day end and weekday
revenues_table$day_start, revenues_table$day_end, as.character(revenues_table$weekday),
# cumulative NGUs
sapply(1:analysis_period, function(d) sum(NGU_per_day$NGU_actual[NGU_per_day$days_since_campaign>=0][1:d])),
# cumulative revenues
round(
sapply(1:analysis_period, function(d) sum((revenues_per_day$revenues_actual
- revenues_per_day$revenues_actual_nonNGU
)[revenues_per_day$days_since_campaign>=0][1:d]))
),
# RPI
round(
sapply(1:analysis_period, function(d) sum((revenues_per_day$revenues_actual
- revenues_per_day$revenues_actual_nonNGU
)[revenues_per_day$days_since_campaign>=0][1:d]))
/sapply(1:analysis_period, function(d) sum(NGU_per_day$NGU_actual[NGU_per_day$days_since_campaign>=0][1:d]))
, 3)
)
colnames(campaign_RPI_table) <- c("day_start", "day_end", "weekday", "cumulative NGUs", "cumulative revenues", "RPI")
NGU_plot_per_day
NGU_plot_per_hour
spark_home<-"/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7"
Sys.setenv(SPARK_HOME = spark_home)
spark_bin <- paste0(spark_home, '/bin')
Sys.setenv(PATH = paste(Sys.getenv(c('PATH')), spark_bin, sep=':'))
hadoop_home <- "/usr/lib/hadoop/"
postgresql_drv <- "/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/postgresql-9.4.1212.jar"
if(!file.exists(postgresql_drv)){
system('curl "https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar" -o "~/Desktop/projects/payer_again/spark_scripts/local_test/"')
}
spark_link <- "local[*]"
spark_bin
library(SparkR, lib.loc = "/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7/R/lib/")
Sys.setenv('SPARKR_SUBMIT_ARGS'='"--packages" "com.databricks:spark-csv_2.10:1.3.0" "sparkr-shell"')
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
spark_home<-"/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7"
Sys.setenv(SPARK_HOME = spark_home)
spark_bin <- paste0(spark_home, '/bin')
Sys.setenv(PATH = paste(Sys.getenv(c('PATH')), spark_bin, sep=':'))
hadoop_home <- "/usr/lib/hadoop/"
Sys.setenv(HADOOP_HOME = hadoop_home) # hadoop-common missing on Windows
postgresql_drv <- "/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/postgresql-9.4.1212.jar"
if(!file.exists(postgresql_drv)){
system('curl "https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar" -o "~/Desktop/projects/payer_again/spark_scripts/local_test/"')
}
spark_link <- "local[*]"
library(SparkR, lib.loc = "/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7/R/lib/")
Sys.setenv('SPARKR_SUBMIT_ARGS'='"--packages" "com.databricks:spark-csv_2.10:1.3.0" "sparkr-shell"')
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sparkR.version()
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
setwd("/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/src")
print(paste(base::date(), " Starting Spark Payer Again DC Training"))
options(java.parameters = "-Xmx30g")
refreshDataTables_inredshift<-TRUE
source("./loadPackages.R")
spark_home<-"/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7"
Sys.setenv(SPARK_HOME = spark_home)
spark_bin <- paste0(spark_home, '/bin')
Sys.setenv(PATH = paste(Sys.getenv(c('PATH')), spark_bin, sep=':'))
hadoop_home <- "/usr/lib/hadoop/"
Sys.setenv(HADOOP_HOME = hadoop_home) # hadoop-common missing on Windows
postgresql_drv <- "/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/postgresql-9.4.1212.jar"
if(!file.exists(postgresql_drv)){
system('curl "https://jdbc.postgresql.org/download/postgresql-9.4.1212.jar" -o "~/Desktop/projects/payer_again/spark_scripts/local_test/"')
}
spark_link <- "local[*]"
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR, lib.loc = "/Users/angus.mckay/spark/spark-2.1.1-bin-hadoop2.7/R/lib/")
Sys.setenv('SPARKR_SUBMIT_ARGS'='"--packages" "com.databricks:spark-csv_2.10:1.3.0" "sparkr-shell"')
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
Sys.getenv(c('PATH'))
?sparkR.session()
JAVA_HOME
Sys.getenv(c('PATH'))
java_home = "/Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java"
Sys.setenv(JAVA_HOME = java_home)
Sys.getenv(c('PATH'))
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
java_home = "/Library/Internet\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java"
Sys.setenv(JAVA_HOME = java_home)
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
java_home = "/Library/Internet\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home"
Sys.setenv(JAVA_HOME = java_home)
sc <- sparkR.session(master = spark_link, appName = "SparkR_local",
sparkEnvir = list(spark.driver.extraClassPath = postgresql_drv),
sparkJars = postgresql_drv,
sparkPackages = c("com.databricks:spark-csv_2.10:1.3.0"),
sparkConfig = list(spark.driver.memory = "100g"))
source("./loadPackages.R")
source("./test_accuracies.R")
payer_again_data <- readRDS("../input_data/training_data2016-09-01.rds")
payer_again_data_dt <- createDataFrame(payer_again_data)
payer_again_data_train <- sample(payer_again_data_dt, withReplacement = FALSE, fraction = 0.7, seed = 123)
payer_again_data_test  <- except(payer_again_data_dt, payer_again_data_train)
print(paste(base::date(), " Creating Random Forest Models"))
rf_model <- spark.randomForest(payer_again_data_train,  future_payer ~  sex + days_since_transaction + android + ios + amount_gross + level + days_since_register + first_buy + total_spend +  transaction_count + minutes_since_prev + game_start_gold + game_start_xp + game_start_food + game_start_cash + game_start_level + game_start_num_expansions + game_start_num_dragons + game_start_num_dragons_legend + game_start_num_habitats + session_length + total_sessions + avg_session_length + sessions_per_week + total_sessions_last2days + total_videoads + videoads_per_week + total_videoads_last7days + au + ca + de + es + fr + gb + us + other_countries, "regression")
View(payer_again_data)
View(payer_again_data)
typeof(payer_again_data)
colnames(payer_again_data)
colnames(payer_again_data)[28]
colnames(payer_again_data)[28] = 'total_videoads'
colnames(payer_again_data)
dates <- list('2016-09-01', '2016-09-09', '2016-09-17', '2016-09-25', '2016-10-03', '2016-10-11', '2016-10-19')
saveRDS(payer_again_data, file=paste0("~/Desktop/projects/Previous payer/spark scripts/input_data/training_data",dates[[1]],".rds"))
saveRDS(payer_again_data, file=paste0("~/Desktop/projects/payer_again/spark_scripts/input_data/training_data",dates[[1]],".rds"))
saveRDS(payer_again_data, file=paste0("~/Desktop/projects/payer_again/spark_scripts/local_test/input_data/training_data",dates[[1]],".rds"))
payer_again_data <- readRDS("../input_data/training_data2016-09-01.rds")
colnames(payer_again_data)
payer_again_data_train <- sample(payer_again_data_dt, withReplacement = FALSE, fraction = 0.7, seed = 123)
payer_again_data_dt <- createDataFrame(payer_again_data)
payer_again_data_train <- sample(payer_again_data_dt, withReplacement = FALSE, fraction = 0.7, seed = 123)
payer_again_data_test  <- except(payer_again_data_dt, payer_again_data_train)
print(paste(base::date(), " Creating Random Forest Models"))
rf_model <- spark.randomForest(payer_again_data_train,  future_payer ~  sex + days_since_transaction + android + ios + amount_gross + level + days_since_register + first_buy + total_spend +  transaction_count + minutes_since_prev + game_start_gold + game_start_xp + game_start_food + game_start_cash + game_start_level + game_start_num_expansions + game_start_num_dragons + game_start_num_dragons_legend + game_start_num_habitats + session_length + total_sessions + avg_session_length + sessions_per_week + total_sessions_last2days + total_videoads + videoads_per_week + total_videoads_last7days + au + ca + de + es + fr + gb + us + other_countries, "regression")
rf_model
pred_rf <- predict(rf_model, payer_again_data_test)
acc_rf <- acc_function(predicted = as.numeric(collect(pred_rf)$prediction), real = as.numeric(collect(payer_again_data_test)$future_payer))
print(acc_rf)
rf_mode
rf_model
rf_model$sc
rf_model['sc']
rf_model[sc]
rf_model
payer_again_data_test$future_payer
payer_again_data_test$future_payer==1
rf_model2 <- spark.randomForest(payer_again_data_train[1:1000,],  future_payer ~  sex + days_since_transaction + android + ios + amount_gross + level + days_since_register + first_buy + total_spend +  transaction_count + minutes_since_prev + game_start_gold + game_start_xp + game_start_food + game_start_cash + game_start_level + game_start_num_expansions + game_start_num_dragons + game_start_num_dragons_legend + game_start_num_habitats + session_length + total_sessions + avg_session_length + sessions_per_week + total_sessions_last2days + total_videoads + videoads_per_week + total_videoads_last7days + au + ca + de + es + fr + gb + us + other_countries, "regression")
payer_again_data_train[1:1000,]
payer_again_data_train[,]
payer_again_data_train[1,]
payer_again_data_train[]
payer_again_data2 <- payer_again_data[1:1000,]
payer_again_data_train2 <- sample(payer_again_data_dt2, withReplacement = FALSE, fraction = 0.7, seed = 123)
payer_again_data_dt2 <- createDataFrame(payer_again_data2)
payer_again_data_train2 <- sample(payer_again_data_dt2, withReplacement = FALSE, fraction = 0.7, seed = 123)
payer_again_data_test2  <- except(payer_again_data_dt2, payer_again_data_train2)
rf_model2 <- spark.randomForest(payer_again_data_train2,  future_payer ~  sex + days_since_transaction + android + ios + amount_gross + level + days_since_register + first_buy + total_spend +  transaction_count + minutes_since_prev + game_start_gold + game_start_xp + game_start_food + game_start_cash + game_start_level + game_start_num_expansions + game_start_num_dragons + game_start_num_dragons_legend + game_start_num_habitats + session_length + total_sessions + avg_session_length + sessions_per_week + total_sessions_last2days + total_videoads + videoads_per_week + total_videoads_last7days + au + ca + de + es + fr + gb + us + other_countries, "regression")
pred_rf2 <- predict(rf_model2, payer_again_data_test2)
pred_rf2
collect(pred_rf2)
acc_rf2 <- acc_function(predicted = as.numeric(collect(pred_rf2)$prediction), real = as.numeric(collect(payer_again_data_test)$future_payer))
acc_rf2 <- acc_function(predicted = as.numeric(collect(pred_rf2)$prediction), real = as.numeric(collect(payer_again_data_test2)$future_payer))
acc_rf2 <- acc_function(predicted = as.numeric(collect(pred_rf2)$prediction), real = as.numeric(collect(payer_again_data_test2)$future_payer))
rm(pred_rf2, payer_again_data2, payer_again_data_dt2)
rm(payer_again_data_test2, payer_again_data_train2)
rm(rf_model2)
rf_predictions <- collect(pred_rf)$prediction
pred_rf <- predict(rf_model, payer_again_data_test)
rf_model <- spark.randomForest(payer_again_data_train,  future_payer ~  sex + days_since_transaction + android + ios + amount_gross + level + days_since_register + first_buy + total_spend +  transaction_count + minutes_since_prev + game_start_gold + game_start_xp + game_start_food + game_start_cash + game_start_level + game_start_num_expansions + game_start_num_dragons + game_start_num_dragons_legend + game_start_num_habitats + session_length + total_sessions + avg_session_length + sessions_per_week + total_sessions_last2days + total_videoads + videoads_per_week + total_videoads_last7days + au + ca + de + es + fr + gb + us + other_countries, "regression")
payer_again_data_dt <- createDataFrame(payer_again_data)
payer_again_data <- readRDS("../input_data/training_data2016-09-01.rds")
payer_again_data_dt <- createDataFrame(payer_again_data)
source("./set_spark_session.R")
1+1
write.ml(object = rf_model, path = paste0("/Users/angus.mckay/Desktop/projects/payer_again/spark_scripts/local_test/current_model"))
